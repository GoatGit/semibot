# Semibot 产品需求文档 (PRD)

| 版本 | 日期       | 状态 | 作者            |
| :--- | :--------- | :--- | :-------------- |
| 1.0  | 2026-02-04 | 草稿 | AI Agent 架构师 |

## 1. 产品愿景

构建一个**极简、通用、云原生**的 Agent 平台，通过灵活且先进的运行时环境，赋能开发者编排复杂的 AI 行为。平台推崇“组合优于配置”的理念，采用 API 层（Node.js）与执行运行时（Python）分离的架构设计。

## 2. 目标受众

- **开发者**：需要一个可编程、可扩展的框架来构建自定义 Agent。
- **企业**：需要一个可扩展、安全的生态系统来部署多 Agent 系统以实现业务自动化。

## 3. 核心设计原则 (源自原始需求)

1. **极致极简**：保持组件松耦合且轻量化。
2. **云原生**：专为 Serverless 环境设计 (Vercel + Modal/Fly.io)。
3. **关注点分离**：前端 (Next.js)、API (Node.js)、运行时 (Python) 相互独立。
4. **开放范式**：类似 OpenClaw/LangGraph 的状态编排机制。
5. **多租户**：内置组织级隔离。

## 4. 功能需求

### 4.1 Agent 核心系统

> 参考: FR-CORE

- **Agent 定义**：用户必须能够定义具有特定角色、目标（系统提示词）和配置（模型配对）的 Agent。
- **状态机执行**：运行时必须基于有限状态机执行 Agent (Start -> Plan -> Act -> Observe -> Reflect)。
- **多 Agent 委派**：Agent 必须能够生成或将任务委派给 **Sub-Agents（子智能体）** 以处理专门的子任务。

### 4.2 技能与工具生态系统

> 参考: FR-SKILL

- **工具 (Tools)**：执行的最小原子单元（例如：“搜索 Google”、“运行 Python 代码”）。
  - 支持 API 调用、代码执行和数据库查询。
  - 支持 MCP (Model Context Protocol) 以面向未来扩展。
- **技能 (Skills)**：组合多个工具的高级能力（例如：“研究技能”包含搜索 + 抓取 + 总结）。
- **注册中心**：用于注册、发现以及将技能/工具绑定到 Agent 的系统。

### 4.3 记忆与上下文

> 参考: FR-MEM

- **短期记忆**：基于会话的上下文管理 (Redis)，用于处理当前活跃的对话。
- **长期记忆**：基于向量的语义存储 (PostgreSQL + pgvector)，用于回忆过去的经验和事实。
- **上下文加载**：根据当前意图自动将相关记忆注入到提示词上下文中。

### 4.4 可观测性与计量

> 参考: FR-OBS

- **执行日志**：详细记录 Agent 思考过程的分步日志（计划、执行、结果）。
- **使用量计量**：跟踪每个租户/用户/Agent 的 Token 使用量、API 调用次数和计算时长。
- **实时反馈**：支持向客户端推送流式响应 (SSE)，提供即时反馈。

### 4.5 API 与集成

> 参考: FR-API

- **RESTful API**：用于管理 Agent、会话和技能的综合端点。
- **异步处理**：耗时任务必须通过队列 (Redis) 处理，以确保系统响应速度。
- **安全性**：支持 API Key 和基于 JWT 的用户认证。

### 4.6 多语言支持（国际化）

> 参考: FR-I18N

- **API 响应国际化**：所有 API 错误消息和提示必须支持多语言，通过 `Accept-Language` 头指定。
- **Agent 多语言**：Agent 的系统提示词和响应支持多语言配置。
- **管理界面多语言**：前端 UI 支持中文、英文等主要语言切换。
- **错误消息多语言**：所有错误码对应的消息支持多语言翻译。

### 4.7 多模型支持

> 参考: FR-MODEL

- **统一适配层**：提供统一的 LLM Provider 接口，屏蔽不同模型的差异。
- **支持的模型**：
  - OpenAI (GPT-4o, GPT-4o-mini, o1 系列)
  - Anthropic (Claude 3.5 Sonnet, Claude 3 Opus)
  - Google (Gemini Pro, Gemini Ultra)
  - 本地模型 (Ollama, vLLM)
- **模型降级**：主模型不可用时自动切换到备用模型。
- **模型路由**：根据任务类型自动选择最优模型。

### 4.8 测试框架

> 参考: FR-TEST

- **单元测试**：所有核心模块需达到 80%+ 代码覆盖率。
- **集成测试**：API 端点、数据库操作的完整测试。
- **端到端测试**：关键用户流程的 E2E 测试（Playwright）。
- **Agent 测试**：Agent 执行流程的模拟测试和回放测试。
- **性能测试**：并发负载测试，确保系统在高负载下稳定运行。

### 4.9 进化系统

> 参考: FR-EVOLVE

- **技能自生成**：Agent 在成功完成多步骤任务后，自动提炼执行经验为可复用技能。
- **异步进化**：进化流程在 REFLECT 之后异步执行，不阻塞用户响应。
- **质量控制**：进化技能需经过质量评分和人工审核（或高质量自动通过）。
- **技能复用**：PLAN 阶段自动检索进化技能库，复用已有技能避免重复劳动。
- **退化处理**：自动监控技能复用效果，低质量技能自动废弃。

## 5. 非功能需求

### 5.1 可扩展性

- **Serverless**：系统必须能够在空闲时缩容至零，并在负载下瞬间扩容。
- **无状态 API**：API 节点不应持有状态；所有状态必须存储在 Redis/Postgres 中。

### 5.2 架构约束

- **后端**：Node.js (Next.js/Express) 用于 API 网关和业务逻辑。
- **运行时**：Python 用于处理繁重的 Agent 编排 (兼容 LangGraph)。
- **数据库**：PostgreSQL 用于关系型数据；pgvector 用于向量嵌入。
- **缓存/队列**：Redis 用于热数据和任务缓冲。

### 5.3 性能

- **延迟**：非阻塞调用的 API 响应时间 < 100ms。
- **并发**：支持在单个 Agent 步骤中并行执行工具。

## 6. 执行流程 (SOP)

1. **输入**：用户定义目标。
2. **计划**：Agent 解析意图并将其分解为步骤的有向无环图 (DAG)。
3. **执行**：
   - 调用工具（尽可能并行）。
   - 委派给子 Agent。
4. **观察**：评估工具输出。
5. **反思**：自我修正或存储学到的知识。
6. **响应**：向用户交付最终答案。

## 7. 未来规划 (Post-MVP)

- 可视化拖与放 Agent 构建器。
- 技能/Agent 共享市场。
- 专用 Agent 模型的微调流水线。
- Agent 自适应进化（Phase 2）：基于技能使用反馈优化 Agent 决策策略。
